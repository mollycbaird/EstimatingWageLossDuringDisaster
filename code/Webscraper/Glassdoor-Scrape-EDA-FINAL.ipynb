{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlassDoor Scrape Analysis and Function\n",
    "## Table of Contents\n",
    "- [Brief EDA](#Brief-EDA)\n",
    "- [Data Scrape - Selenium (with Problem Statement)](#Data-Scrape---Selenium)\n",
    "- [Final Working Function](#Final-Working-Function)\n",
    "- [Takeaways and conclusion](#Takeaways-and-conclusion)\n",
    "- [Example Codes](#Example-Codes)\n",
    "\n",
    "\n",
    "## Executive Summary:\n",
    "We were able to successfully build a scraper. \n",
    "- Inputs: keyword, location(optional). \n",
    "- Outputs: City, State, Jobname, Average Salary, quantity of postings sorted by elapsed days\n",
    "\n",
    "Our intended use of this scraper is to capture live job list and wage data, and return the information in a format that can be iterated over for building a data frame. State and City will match search criteria from our main DataFrame. How we use the scraper will depend on the use-case and context, for now it will be to capture basic job information alongside the functionality of being able to iterate and build a dataframe over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sources:\n",
    "- [Glass Door Developer Page](https://www.glassdoor.com/developer/index.htm) : Dev page for API scrape\n",
    "- [Glass Door first URL](https://www.glassdoor.com/Job/index.htm) : Initial URL\n",
    "- [Glass Door final URL](https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientes&sc.keyword=data+scientest&locT=&locId=&jobType=) : Final URL that worked with our scraper\n",
    "- [Glassdoor scrape example - Selenium (git)](https://github.com/arapfaik/scraping-glassdoor-selenium) : github link to author of Medium article\n",
    "- [Glassdoor scrape example - Selenium (Medium)](https://medium.com/@jamievaron/to-anyone-who-has-lost-themselves-9c5e3049cb13) : Link to Medium article covering Glassdoor and Selenium\n",
    "- [Selenium Review SEA-FLEX-11](https://git.generalassemb.ly/charles-rice/SEA-Flex-11/tree/master/08_week/selenium-webscraping) : Selenium flex review lab completed with our instructor.\n",
    "- [Xpath guide](https://devhints.io/xpath) : reference guide for Xpath commands\n",
    "- [Selenium Keys_Input Documentation](https://selenium-python.readthedocs.io/api.html) : reference guide for special keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "df = pd.read_csv('../data/main_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterNumber</th>\n",
       "      <th>state</th>\n",
       "      <th>incidentType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>occ_code</th>\n",
       "      <th>occ_title</th>\n",
       "      <th>tot_emp</th>\n",
       "      <th>h_mean</th>\n",
       "      <th>a_mean</th>\n",
       "      <th>employment_rate_during</th>\n",
       "      <th>employment_rate_before</th>\n",
       "      <th>employment_rate_after</th>\n",
       "      <th>employment_rate_change</th>\n",
       "      <th>wage_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190</td>\n",
       "      <td>NE</td>\n",
       "      <td>Severe Storm(s)</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13002</td>\n",
       "      <td>Financial Managers</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>50960</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-43864.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190</td>\n",
       "      <td>NE</td>\n",
       "      <td>Severe Storm(s)</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13005</td>\n",
       "      <td>Personnel, Training, and Labor Relations Managers</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>21.41</td>\n",
       "      <td>44540</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-14593.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disasterNumber state     incidentType    year  month occ_code  \\\n",
       "0            1190    NE  Severe Storm(s)  1997.0   11.0    13002   \n",
       "1            1190    NE  Severe Storm(s)  1997.0   11.0    13005   \n",
       "\n",
       "                                           occ_title  tot_emp  h_mean a_mean  \\\n",
       "0                                 Financial Managers   3730.0   24.50  50960   \n",
       "1  Personnel, Training, and Labor Relations Managers   1420.0   21.41  44540   \n",
       "\n",
       "   employment_rate_during  employment_rate_before  employment_rate_after  \\\n",
       "0                    71.5                    71.5                   71.6   \n",
       "1                    71.5                    71.5                   71.6   \n",
       "\n",
       "   employment_rate_change  wage_change  \n",
       "0                    -0.1   -43864.800  \n",
       "1                    -0.1   -14593.056  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the head, verify columns and information\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disasterNumber', 'state', 'incidentType', 'year', 'month', 'occ_code',\n",
       "       'occ_title', 'tot_emp', 'h_mean', 'a_mean', 'employment_rate_during',\n",
       "       'employment_rate_before', 'employment_rate_after',\n",
       "       'employment_rate_change', 'wage_change'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify columns look clean, no mistakes slipped in\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disasterNumber              int64\n",
       "state                      object\n",
       "incidentType               object\n",
       "year                      float64\n",
       "month                     float64\n",
       "occ_code                   object\n",
       "occ_title                  object\n",
       "tot_emp                   float64\n",
       "h_mean                    float64\n",
       "a_mean                     object\n",
       "employment_rate_during    float64\n",
       "employment_rate_before    float64\n",
       "employment_rate_after     float64\n",
       "employment_rate_change    float64\n",
       "wage_change               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic eda of dtypes for future references\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We seek categorize each of business types/categories in our main df. This is a shared code ran by each member\n",
    "## of our group who is working with this dataframe.\n",
    "\n",
    "# Code from Patrick Kajibale \n",
    "df['Business_type']= df['occ_code'].apply(lambda x : x[:2])\n",
    "#pd.set_option('display.max_row()',None)\n",
    "industry = {\n",
    "        '13' :'Business and Financial Operations',\n",
    "        '15' :'Computer and Mathematical',\n",
    "        '17' :'Architecture and Engineering',\n",
    "        '19' :'Life, Physical, and Social Science',\n",
    "        '21' :'Community and Social Service',\n",
    "        '23' :'Legal',\n",
    "        '25' :'Educational Instruction and Library',\n",
    "        '27' :'Arts, Design, Entertainment, Sports, and Media',\n",
    "        '29' :'Healthcare Practitioners and Technical',\n",
    "        '31' :'Healthcare Support',\n",
    "        '33' :'Protective Service',\n",
    "        '35' :'Food Preparation and Serving Related',\n",
    "        '37' :'Building and Grounds Cleaning and Maintenance',\n",
    "        '39' :'Personal Care and Service',\n",
    "        '41' :'Sales and Related',\n",
    "        '43' :'Office and Administrative Support',\n",
    "        '45' :'Farming, Fishing, and Forestry',\n",
    "        '47' :'Construction and Extraction',\n",
    "        '49' :'Installation, Maintenance, and Repair',\n",
    "        '51' :'Production',\n",
    "        '53' :'Transportation and Material Moving'}\n",
    "df['Business_type'].replace(industry, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterNumber</th>\n",
       "      <th>state</th>\n",
       "      <th>incidentType</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>occ_code</th>\n",
       "      <th>occ_title</th>\n",
       "      <th>tot_emp</th>\n",
       "      <th>h_mean</th>\n",
       "      <th>a_mean</th>\n",
       "      <th>employment_rate_during</th>\n",
       "      <th>employment_rate_before</th>\n",
       "      <th>employment_rate_after</th>\n",
       "      <th>employment_rate_change</th>\n",
       "      <th>wage_change</th>\n",
       "      <th>Business_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1190</td>\n",
       "      <td>NE</td>\n",
       "      <td>Severe Storm(s)</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13002</td>\n",
       "      <td>Financial Managers</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>50960</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-43864.800</td>\n",
       "      <td>Business and Financial Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1190</td>\n",
       "      <td>NE</td>\n",
       "      <td>Severe Storm(s)</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13005</td>\n",
       "      <td>Personnel, Training, and Labor Relations Managers</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>21.41</td>\n",
       "      <td>44540</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-14593.056</td>\n",
       "      <td>Business and Financial Operations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disasterNumber state     incidentType    year  month occ_code  \\\n",
       "0            1190    NE  Severe Storm(s)  1997.0   11.0    13002   \n",
       "1            1190    NE  Severe Storm(s)  1997.0   11.0    13005   \n",
       "\n",
       "                                           occ_title  tot_emp  h_mean a_mean  \\\n",
       "0                                 Financial Managers   3730.0   24.50  50960   \n",
       "1  Personnel, Training, and Labor Relations Managers   1420.0   21.41  44540   \n",
       "\n",
       "   employment_rate_during  employment_rate_before  employment_rate_after  \\\n",
       "0                    71.5                    71.5                   71.6   \n",
       "1                    71.5                    71.5                   71.6   \n",
       "\n",
       "   employment_rate_change  wage_change                      Business_type  \n",
       "0                    -0.1   -43864.800  Business and Financial Operations  \n",
       "1                    -0.1   -14593.056  Business and Financial Operations  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)\n",
    "## we'll keep business_type categorization in case we need it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing else from the dataset is needed for now as we focus on scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scrape - Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial workflow is as such:\n",
    "1. Establish a working cell that: opens page successfully\n",
    "2. Build a function that can output some piece of information as a page (a test)\n",
    "3. Continue to iterate function to include more extraction features<br>\n",
    "### Problem Statement: \n",
    "We want a function that can scrape glass door's job listings based on name and location, and return the average salary, location, and listing quantities. Our goal is to have a scraper that can assist with building a database from live listings to report and model on during/after a major disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "I referenced two examples of Selenium usage\n",
    "##### Medium/Github\n",
    " - This was a medium article and jupyter notebook (pulled from github) containing a dataframe scrape function.\n",
    " - A few issues I had with this was:\n",
    "  - Base URL had embedded location and preferences, thus the tool only worked for that area. \n",
    "  - Next, GlassDoor has some anti-scrape methods that prevent customizing search selections via url code, no matter what you type for key word, it would select a location (with keyed ID number) and insert that into the URL for search criteria. **This is where selenium's human impersonations work** \n",
    "  - This code did direct me into reading more about XPath, how it works, and using it for building data frames.\n",
    " \n",
    "\n",
    "##### SEA-Flex-11 \n",
    " - The Second guide I used was a recording from our local instructor and Data aficionado\n",
    " - Taught me how to interact beautiful soup alongside Selenium.\n",
    " - Code included examples of mimicking human operations, I studied this extensively\n",
    " - THANK YOU AS ALWAYS CHARLIE!\n",
    " \n",
    " \n",
    "##### Last notes before Function Code \n",
    "- A guide used suggests I will experience a pop-up to sign up for Glassdoor.\n",
    " - I am not experiencing a log-in prompt every time I click, I will include this code as a net in case this is dependent on mine own machine\n",
    "  - This is not included in the current running code\n",
    " - `options.add_argument(‘headless’)` to bypass Chrome window opening\n",
    "  - this is not included in the current example\n",
    "\n",
    "\n",
    "#### Failed URL Options:\n",
    "***These are my initial notes and breakdown of url to find a way to specify location***\n",
    "- full search url example:\n",
    " - `https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=&locId=&jobType=`\n",
    " <br><br> What we need is: \n",
    " - `https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=` + *JOBNAME* + `'&locT=&locId=&jobType=\"`\n",
    " - Result: Unfortunately, this resulted in Chrome defaulting to Glassdoor's search homepage. This becomes an issue because of Selenium's interaction with Chrome drivers, GlassDoor would ignore any input we inserted for location and would default to our IP geo-tag. \n",
    " <br>\n",
    " - **Solution**: We simply use a url with results already displayed, as it has `location` and `keyword` search boxes that DO respond to input.\n",
    "  - NOTE: GlassDoor requires that the search url contains a numerical locid locked behind their API. My workaround was to have Selenium arrow-down + tab to select best match. I applied this to both `keyword` search and `location`.\n",
    "  \n",
    "#### Blank search form:\n",
    "- https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=&locT=&locId=&jobType=&context=Jobs&sc.keyword=&dropdown=0\n",
    "- Result: Still defaulted to geo-ip.\n",
    "\n",
    "#### Final URL:\n",
    "- Our best result was opting to input the search bars available on a page already displaying results (as opposed to the Glassdoor Search Homepage and its resulting auto-location issues.\n",
    "- https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1138213&jobType=\n",
    "- Result: It's a nice nod to Data Science and a workaround our problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search Dictionary:\n",
    "- `typedKeyword=&` >> captures job search input in search bar\n",
    "- `sc.keyword=&` >> mimics above\n",
    "- `locT=&` >> required* numerical\n",
    "- `locId=&` >> required* numerical\n",
    "- `jobType=` >> unused\n",
    "\n",
    "Notes: Originally I was tracking url indexing for search terms, ultimately I found that tinkering with these resulted poorly as Glassdoor masks a lot of their categories (location id, settings functionality, etc) behind numerical ids with no key. API is also very restrictive, requiring a partner's license to access (we were denied)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Step: Ensure we can open Glass door."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url for test\n",
    "# this url will take us to a blank search page with 'Jobs' and 'Location' \n",
    "url = 'https://www.glassdoor.com/Job/index.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this opens upa. page with two search criteria, Job Title, and Area. \n",
    "# we will have to mimic clicking and entering our inputs for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Elements:\n",
    "This is a reference page I built out for tracking the two search bars from a clean page and a page with results already displayed. The **2nd attempt** was our working url and searchbar combo.\n",
    "\n",
    "\n",
    "#### Job Search Bar\n",
    "**Xpath**<br>`//*[@id=\"LocationSearch\"]//div[1]` <br>\n",
    "**HTML** <br> `<input id=\"LocationSearch\" class=\"loc\" type=\"text\" tabindex=\"0\" value=\"Bellevue, WA\" data-srch-type=\"popular\" data-test=\"search-bar-location-input\" placeholder=\"Location\" aria-label=\"Location\">`\n",
    "\n",
    "#### Location Search Bar\n",
    "**Xpath** <br> `//*[@id=\"LocationSearch\"]`\n",
    "**HTML** <br> `<input id=\"LocationSearch\" class=\"loc\" type=\"text\" tabindex=\"0\" value=\"Bellevue, WA\" data-srch-type=\"popular\" data-test=\"search-bar-location-input\" placeholder=\"Location\" aria-label=\"Location\">`\n",
    "\n",
    "\n",
    "## 2nd attempt, via new hyperlink\n",
    "#### Job Search Bar\n",
    "**Xpath**<br>`//*[@id=\"sc.keyword\"]` <br>\n",
    "**HTML** <br> `<input name=\"sc.keyword\" id=\"sc.keyword\" class=\"keyword\" type=\"text\" tabindex=\"0\" value=\"\" placeholder=\"Job Title, Keywords, or Company\" data-auto-complete=\"true\" data-ac-version=\"New\" data-test=\"search-bar-keyword-input\" aria-label=\"Keyword\" autocomplete=\"off\">`\n",
    "\n",
    "#### Location Search Bar\n",
    "**Xpath** <br> `//*[@id=\"sc.location\"]`\n",
    "**HTML** <br> `<input id=\"sc.location\" class=\"loc\" type=\"text\" tabindex=\"0\" value=\"Bellevue, WA\" data-srch-type=\"popular\" data-test=\"search-bar-location-input\" placeholder=\"Location\" aria-label=\"Location\" autocomplete=\"off\">`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Step: build a function that successfully navigates us to the requested search page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_track(keyword, location = None):\n",
    "    # query chrome driver for selenium\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "    \n",
    "    # set url\n",
    "    url = 'https://www.glassdoor.com/Job/index.htm'\n",
    "    \n",
    "    # execute driver on url\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #locates the search field specifying 'Job Title, Keyewards, or Company'\n",
    "    kw = driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]')\n",
    "    kw.clear()\n",
    "    kw.send_keys(keyword)\n",
    "    sleep(2)\n",
    "    #locates the search field specifying 'Location'\n",
    "    ## current issue is html/glassdoor default your location by mac/ip\n",
    "    ## so we are manually entering our location search as a possible field\n",
    "    loc = driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]')\n",
    "    loc.clear()\n",
    "    loc.send_keys(location)\n",
    "    sleep(2)\n",
    "    loc.send_keys(u'\\ue006')\n",
    "    \n",
    "    # and we xpath the search button to click search\n",
    "#     click = driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]')\n",
    "#     click.click()\n",
    "    sleep(1)\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_track('data scientist', location = 'Virginia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: So, this works, but regardless of location input glassdoor overwrites your location with their handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 revised: changing url to that of returned results (still has access to search bars)\n",
    "Our idea is to test the autocompletion and bypass it by being able to locate and input our location query, adding lag delay and clicking first option from the search menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running a test cell to verify new url works\n",
    "# changing url - this cell was ran to verify our search bars updated\n",
    "url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1138213&jobType=\"\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "sleep(2)\n",
    "driver.close()\n",
    "\n",
    "# this is only needed if page waits too long, it closes the pop-up I've only seen occur once.\n",
    "# driver.find_element_by_class_name(\"qual_x_svg_X\").click()\n",
    "\n",
    "## below are the search bar xpath locations\n",
    "# kw = driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]')    # searches key word\n",
    "# loc = driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]')  # searches location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... Now I try extracting information and processing it for dataframe building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just rebuild the function with the new url and test\n",
    "def job_track(keyword, location = None):\n",
    "    ''' This function simply takes a job name and location, opens up glassdoor\n",
    "    and searches your criteria and returns how many listings are available in that area'''\n",
    "    # set base url\n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1138213&jobType=\"\n",
    "    # query chrome driver for selenium\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "    \n",
    "    # execute driver on url\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #locates the search field specifying 'Job Title, Keyewards, or Company'\n",
    "    kw = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[5]')\n",
    "    kw.clear()\n",
    "    kw.send_keys(keyword)\n",
    "    sleep(1)\n",
    "    kw.send_keys(u'\\ue015') # down arrow\n",
    "    sleep(1)\n",
    "    kw.send_keys(u'\\ue004') # tab to select closest match\n",
    "    sleep(1)\n",
    "    #locates the search field specifying 'Location'\n",
    "    ## current issue is html/glassdoor default your location by mac/ip\n",
    "    ## so we are manually entering our location search as a possible field\n",
    "    loc = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[6]')\n",
    "    loc.clear()\n",
    "    loc.send_keys(location)\n",
    "    sleep(1)\n",
    "    loc.send_keys(u'\\ue015') # down arrow\n",
    "    sleep(1)\n",
    "    loc.send_keys(u'\\ue004') # tab to select closest match\n",
    "    sleep(1)\n",
    "    \n",
    "    # and we xpath the search button to click search\n",
    "    click = driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]/span')\n",
    "    click.click()\n",
    "    sleep(.1)\n",
    "    driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_track(\"data scientist\", 'bellevue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... now let's try extracting information from the new page\n",
    "- note: we had to tell the function to update the new url once it opened up search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we extract information, let's pull total listings\n",
    "## confirmed working function!\n",
    "def total_listings(keyword, location = None):\n",
    "    ''' This function simply takes a job name and location, opens up glassdoor\n",
    "    and returns the number of available. jobs in that area''' \n",
    "    # set base url\n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1138213&jobType=\"\n",
    "    # query chrome driver for selenium\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "    \n",
    "    # execute driver on url\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #locates the search field specifying 'Job Title, Keyewards, or Company'\n",
    "    kw = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[5]')\n",
    "    kw.clear()\n",
    "    kw.send_keys(keyword)   # enters keyword search (Job name preferably)\n",
    "    sleep(1)\n",
    "    kw.send_keys(u'\\ue015') # down arrow\n",
    "    sleep(1)\n",
    "    kw.send_keys(u'\\ue004') # tab to select closest match\n",
    "    sleep(1)\n",
    "    #locates the search field specifying 'Location'\n",
    "    ## current issue is html/glassdoor default your location by mac/ip\n",
    "    ## so we are manually entering our location search as a possible field\n",
    "    loc = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[6]')\n",
    "    loc.clear()\n",
    "    loc.send_keys(location)  # enters location details in location search\n",
    "    sleep(1)\n",
    "    loc.send_keys(u'\\ue015') # down arrow\n",
    "    sleep(1)\n",
    "    loc.send_keys(u'\\ue004') # tab to select closest match\n",
    "    sleep(1)\n",
    "    \n",
    "    # and we xpath the search button to click search\n",
    "    click = driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]/span') \n",
    "    click.click() # boop!\n",
    "    \n",
    "    url = driver.current_url #since we opened a new page, we need to update our url reference\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        text = driver.find_element_by_xpath('//*[@id=\"MainColSummary\"]/div/div/div[2]').text\n",
    "        sleep(.1)\n",
    "        driver.close()\n",
    "    except:\n",
    "        print(\"Please check your search criteria\")\n",
    "        sleep(.1)\n",
    "        driver.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'441 Lead Data Scientist Jobs in Bellevue, WA'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_listings('data scientist', 'Bellevue WA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing string.split for parsing results pulled\n",
    "string = '441 Lead Data Scientist Jobs in Bellevue, WA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'441'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.split(' ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Working Function\n",
    "- here we have a scraper that pulls job information based on:\n",
    "<br><t>**inputs** \n",
    "  - `keyword` : job title/name\n",
    "  - `location` : US-based city or state\n",
    "<br> Our function will bypass login and geo-tracking for auto-completion on searches by using an url source of a completed search. <br><br> Once selenium opens the page, it visits each search bar, inputs our entries, then scrapes hte resulting page into a simple dataframe.<br><br><t>If we choose, we can loop this function over each state in our data frame for a specific job, or even multiple jobs. *Granted*, this is a selenium scrape and is limited by time frame and better used for commenting on current status <br><br><br>\n",
    "##### Another note on `location`\n",
    "Glassdoor does not allow searching off a keyword match for locations (as they do with jobs). Every search will auto-complete onto their string name. In the URL it is coded behind a unique id and id list which they have hidden for anti-scraping purposes. Our solution to this is simply have selenium use the arrow keys to select fist (and typically, best/closest) match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we piece together the original function to return a data frame of our findings\n",
    "\n",
    "def job_status(keyword, location = None):\n",
    "    ''' This function simply takes a job name and location, opens up glassdoor\n",
    "    and returns an informative dataframe regarding the job status and availability''' \n",
    "    # set base url\n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist&sc.keyword=data+scientist&locT=C&locId=1138213&jobType=\"\n",
    "    \n",
    "    # query chrome driver for selenium\n",
    "    driver = webdriver.Chrome(\n",
    "        executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "    \n",
    "    # execute driver on url\n",
    "    driver.get(url)\n",
    "    \n",
    "    #locates the search field specifying 'Job Title, Keywords, or Company'\n",
    "    kw = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[5]')  # locates keyword search bar\n",
    "    \n",
    "    kw.clear()              # clears the search bar\n",
    "    \n",
    "    kw.send_keys(keyword)   # enters our key word\n",
    "    \n",
    "    sleep(.1)\n",
    "    \n",
    "    kw.send_keys(u'\\ue015') # down arrow to select closest match for search (more important for location)\n",
    "    \n",
    "    sleep(.1)\n",
    "    \n",
    "    kw.send_keys(u'\\ue004') # tab to select closest match\n",
    "    \n",
    "    sleep(.1)\n",
    "    \n",
    "    #locates the search field specifying 'Location'\n",
    "    ## current issue is html/glassdoor default your location by mac/ip\n",
    "    ## so we are manually entering our location search as a possible field\n",
    "    loc = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[6]')\n",
    "    loc.clear()              # clears the search bar\n",
    "    loc.send_keys(location)  # updates location\n",
    "    sleep(.1)\n",
    "    loc.send_keys(u'\\ue015') # down arrow\n",
    "    sleep(.1)\n",
    "    loc.send_keys(u'\\ue004') # tab to select closest match\n",
    "    sleep(1)\n",
    "    \n",
    "    # and we xpath the search button to click search\n",
    "    click = driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]/span')\n",
    "    click.click() # boop!\n",
    "    sleep(2)\n",
    "    \n",
    "  \n",
    "    url = driver.current_url #since we opened a new page, we need to update our url reference\n",
    "    driver.get(url)\n",
    "    sleep(.1)\n",
    "    \n",
    "    #now we build our columns\n",
    "    \n",
    "    # empty list that we'll convert into a dataframe\n",
    "    frame = []  \n",
    "    \n",
    "    # add city information\n",
    "    try:\n",
    "        city = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[6]').get_attribute(\"value\").split(',')[0]\n",
    "    except:\n",
    "        city = 'Failed to obtain'\n",
    "    \n",
    "    \n",
    "    # add state information\n",
    "    try:\n",
    "        state = driver.find_element_by_xpath('/html/body/header/div[3]/div[2]/form/input[6]').get_attribute(\"value\").split(',')[1]\n",
    "    except:\n",
    "        state = 'Failed to obtain'\n",
    "    \n",
    "    \n",
    "    # job name\n",
    "    \n",
    "    job_name = keyword\n",
    "    \n",
    "    # total job postings\n",
    "    try:\n",
    "        total_jobs = driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/article/div[1]/div[1]/div/div/div[2]').text.split(' ')[0]\n",
    "    except:                \n",
    "        total_jobs = 'Failed to obtain'\n",
    "\n",
    "    # average salary, replaces K with numerical thousand\n",
    "    try:\n",
    "        avg_salary = driver.find_element_by_xpath('//*[@id=\"filter_minSalary\"]/span[1]').text.replace('K', ',000\\$')\n",
    "    except:\n",
    "        avg_salary = 'Failed to obtain'\n",
    "    \n",
    "    # we need to click a drop down menu to collect job posting quantity details\n",
    "    drop = driver.find_element_by_xpath('//*[@id=\"filter_fromAge\"]/span[1]')\n",
    "    drop.click()\n",
    "\n",
    "\n",
    "    # postings in last 3 days    \n",
    "    try:       \n",
    "        last_3_days =  driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[1]/header/div[2]/ul/li[3]/span[1]/span').text.replace('(', '').replace(')', '')\n",
    "    except:\n",
    "        last_3_days = 'Failed to obtain'\n",
    "\n",
    "\n",
    "    # postings in last week\n",
    "    try:\n",
    "        last_7_days =  driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[1]/header/div[2]/ul/li[4]/span[1]/span').text.replace('(', '').replace(')', '')\n",
    "    except:\n",
    "        last_7_days = 'Failed to obtain'\n",
    "\n",
    "\n",
    "    # last month\n",
    "    try:\n",
    "        last_30_days =  driver.find_element_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[1]/header/div[2]/ul/li[6]/span[1]/span').text.replace('(', '').replace(')', '')\n",
    "    except:\n",
    "        last_30_days = 'Failed to obtain'\n",
    "    \n",
    "    frame.append({\n",
    "        'City' : city,\n",
    "        'State' : state,\n",
    "        'Job' : keyword,\n",
    "        'Total Listings' : total_jobs,\n",
    "        'Average Salary (usd)' : avg_salary,\n",
    "        'Posts (3 days)' : last_3_days,\n",
    "        'Posts (7 days)' : last_7_days,\n",
    "        'Posts (30 Days)' : last_30_days\n",
    "    })\n",
    "    driver.close()\n",
    "    return pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Job</th>\n",
       "      <th>Total Listings</th>\n",
       "      <th>Average Salary (usd)</th>\n",
       "      <th>Posts (3 days)</th>\n",
       "      <th>Posts (7 days)</th>\n",
       "      <th>Posts (30 Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Electrician</td>\n",
       "      <td>109</td>\n",
       "      <td>$16,000\\$-$86,000\\$</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City State          Job Total Listings Average Salary (usd)  \\\n",
       "0  Detroit    MI  Electrician            109  $16,000\\$-$86,000\\$   \n",
       "\n",
       "  Posts (3 days) Posts (7 days) Posts (30 Days)  \n",
       "0             20             35              92  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_status('Electrician', 'Detroit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways and conclusion\n",
    "- *Medium scraper*: too specific, but was a great source of xpath study and interaction with selenium\n",
    "- *GlassDoor*: Plenty of obvious anti scraping methods\n",
    " - Starting with their required partnership to receive a developer's API to access their data\n",
    " - You cannot search glassdoor without creating an account or, if you bypass it via url entry, you will get prompted every click to log in\n",
    " - Geo-tagged IP addresses and location ID's were other forms of anti scrape.\n",
    "\n",
    "- `job_status(keyword, location= None)`\n",
    " - With this function, we can decide how we want to gather our data as we complement the dataset we are using separate of our scrape.\n",
    " - Options: \n",
    "  - iterate over a for loop for each state of a job title, build a data frame\n",
    "  - update code to grab other information, and loop it through several pages\n",
    "  - With enough time, we can attempt timeseries inspections on job postings following disasters.\n",
    "\n",
    "#### Current status:\n",
    "Our requirement of building a scrape tool that can report back current job status, salary, and listings is satisfied.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Glassdoor scrape example - Selenium (git)](https://github.com/arapfaik/scraping-glassdoor-selenium) : github link to author of Medium article\n",
    "- [Glassdoor scrape example - Selenium (Medium)](https://medium.com/@jamievaron/to-anyone-who-has-lost-themselves-9c5e3049cb13) : Link to Medium article covering Glassdoor and Selenium\n",
    "- [Selenium Review SEA-FLEX-11](https://git.generalassemb.ly/charles-rice/SEA-Flex-11/tree/master/08_week/selenium-webscraping) : Selenium flex review lab completed with our instructor.\n",
    "- These are reviewed heavily throughout the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Glassdoor'''\n",
    "    \n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\", options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "\n",
    "    url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=\"' + keyword + '\"&locT=C&locId=1147401&locKeyword=San%20Francisco,%20CA&jobType=all&fromAge=-1&minSalary=0&includeNoSalaryJobs=true&radius=100&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&seniorityType=all&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0'\n",
    "    driver.get(url)\n",
    "    jobs = []\n",
    "\n",
    "    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.\n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "        time.sleep(4)\n",
    "\n",
    "        #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"selected\").click()\n",
    "        except ElementClickInterceptedException:\n",
    "            pass\n",
    "\n",
    "        time.sleep(.1)\n",
    "\n",
    "        try:\n",
    "            driver.find_element_by_class_name(\"ModalStyle__xBtn___29PT9\").click()  #clicking to the X.\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        #Going through each job in this page\n",
    "        job_buttons = driver.find_elements_by_class_name(\"jl\")  #jl for Job Listing. These are the buttons we're going to click.\n",
    "        for job_button in job_buttons:  \n",
    "\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(num_jobs)))\n",
    "            if len(jobs) >= num_jobs:\n",
    "                break\n",
    "\n",
    "            job_button.click()  #You might \n",
    "            time.sleep(1)\n",
    "            collected_successfully = False\n",
    "            \n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    company_name = driver.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "                    location = driver.find_element_by_xpath('.//div[@class=\"location\"]').text\n",
    "                    job_title = driver.find_element_by_xpath('.//div[contains(@class, \"title\")]').text\n",
    "                    job_description = driver.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(5)\n",
    "\n",
    "            try:\n",
    "                salary_estimate = driver.find_element_by_xpath('.//span[@class=\"gray small salary\"]').text\n",
    "            except NoSuchElementException:\n",
    "                salary_estimate = -1 #You need to set a \"not found value. It's important.\"\n",
    "            \n",
    "            try:\n",
    "                rating = driver.find_element_by_xpath('.//span[@class=\"rating\"]').text\n",
    "            except NoSuchElementException:\n",
    "                rating = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "            #Printing for debugging\n",
    "            if verbose:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "                print(\"Job Description: {}\".format(job_description[:500]))\n",
    "                print(\"Rating: {}\".format(rating))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "\n",
    "            #Going to the Company tab...\n",
    "            #clicking on this:\n",
    "            #<div class=\"tab\" data-tab-type=\"overview\"><span>Company</span></div>\n",
    "            try:\n",
    "                driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "\n",
    "                try:\n",
    "                    #<div class=\"infoEntity\">\n",
    "                    #    <label>Headquarters</label>\n",
    "                    #    <span class=\"value\">San Francisco, CA</span>\n",
    "                    #</div>\n",
    "                    headquarters = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Headquarters\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    headquarters = -1\n",
    "\n",
    "                try:\n",
    "                    size = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Size\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    size = -1\n",
    "\n",
    "                try:\n",
    "                    founded = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Founded\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    founded = -1\n",
    "\n",
    "                try:\n",
    "                    type_of_ownership = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Type\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    type_of_ownership = -1\n",
    "\n",
    "                try:\n",
    "                    industry = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Industry\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    industry = -1\n",
    "\n",
    "                try:\n",
    "                    sector = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Sector\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    sector = -1\n",
    "\n",
    "                try:\n",
    "                    revenue = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Revenue\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    revenue = -1\n",
    "\n",
    "                try:\n",
    "                    competitors = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Competitors\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    competitors = -1\n",
    "\n",
    "            except NoSuchElementException:  #Rarely, some job postings do not have the \"Company\" tab.\n",
    "                headquarters = -1\n",
    "                size = -1\n",
    "                founded = -1\n",
    "                type_of_ownership = -1\n",
    "                industry = -1\n",
    "                sector = -1\n",
    "                revenue = -1\n",
    "                competitors = -1\n",
    "\n",
    "                \n",
    "            if verbose:\n",
    "                print(\"Headquarters: {}\".format(headquarters))\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Founded: {}\".format(founded))\n",
    "                print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"Revenue: {}\".format(revenue))\n",
    "                print(\"Competitors: {}\".format(competitors))\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "            jobs.append({\"Job Title\" : job_title,\n",
    "            \"Salary Estimate\" : salary_estimate,\n",
    "            \"Job Description\" : job_description,\n",
    "            \"Rating\" : rating,\n",
    "            \"Company Name\" : company_name,\n",
    "            \"Location\" : location,\n",
    "            \"Headquarters\" : headquarters,\n",
    "            \"Size\" : size,\n",
    "            \"Founded\" : founded,\n",
    "            \"Type of ownership\" : type_of_ownership,\n",
    "            \"Industry\" : industry,\n",
    "            \"Sector\" : sector,\n",
    "            \"Revenue\" : revenue,\n",
    "            \"Competitors\" : competitors})\n",
    "            #add job to jobs\n",
    "\n",
    "        #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//li[@class=\"next\"]//a').click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(jobs)  #This line converts the dictionary object into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From SEA-FLEX-11 review with Charlie Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['name', 'location', 'price', 'cuisine','rating','reviews'])\n",
    "\n",
    "# one big for loop!\n",
    "for row in soup.find_all('div', {'class': 'rest-row-info'}):\n",
    "    name = row.find('span', {'class':'rest-row-name-text'}).text\n",
    "    loc = row.find('span',{'class':'rest-row-meta--location rest-row-meta-text sfx1388addContent'}).text\n",
    "    price = int(row.find('i', {'class':'pricing--the-price'}).text.count('$'))\n",
    "    cuisine = row.find('span', {'class':'rest-row-meta--cuisine rest-row-meta-text sfx1388addContent'}).text\n",
    "    try:\n",
    "        rating = row.find('div',{'class':'star-rating-score'}).attrs['aria-label'].rsplit('s')[0].strip()\n",
    "    except:\n",
    "        rating = 0\n",
    "    try:\n",
    "        reviews = row.find('a',{'class':'review-link'}).find('span').text.strip('()')\n",
    "    except:\n",
    "        reviews = 0\n",
    "    df.loc[len(df)] = [name, loc, price, cuisine, rating, reviews]\n",
    "    \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=\"' + \n",
    "keyword + \n",
    "'\"&locT=C&locId=1147401&locKeyword=San%20Francisco,%20CA&jobType=all&fromAge=-1&minSalary=0&includeNoSalaryJobs=true&radius=100&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&seniorityType=all&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
